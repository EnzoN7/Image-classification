{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projet** : Deep Learning\n",
    "*Par Arthur Couturier, Enzo Di Maria, José Colin, Rémi Bonrepaux & Yassir El Bsita*\n",
    "\n",
    "**Notre objectif est classifier de façon efficace et efficiente des fruits et légumes.**\n",
    "- Pour ce faire, on propose un première base de données, *simple-database*, dans laquelle chaque photo présente un unique fruit sur fond blanc.\n",
    "- Pour complexifier les choses, on optera dans un second temps pour une base de données, *realistic-database*, avec certes moins de classes, mais dont les photos sont moins évidentes, plus réalistes.\n",
    "- Nous déterminerons ensuite les potentiels bienfaits d'une base de données hybride entre la première et la seconde, *hybrid-database*.\n",
    "\n",
    "Enfin, parce que c'est amusant, nous avons soumis les candidats à l'élection présidentielle de 2022 au détecteur de fruit...\n",
    "\n",
    "**Utilisez cette version du document si vous compilez via Google Colab.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Paramètres globaux du document </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "!git clone https://github.com/EnzoN7/Image-classification.git\n",
    "path1 = \"./Image-classification/databases/simple-database/\"\n",
    "path2 = \"./Image-classification/databases/realistic-database/\"\n",
    "path3 = \"./Image-classification/databases/hybrid-database/\"\n",
    "sys.path.insert(1, \"./Image-classification/scripts/\")\n",
    "sys.path.insert(1, \"./Image-classification/models/\")\n",
    "\n",
    "# (1) et (2)\n",
    "from Load import load_data\n",
    "from Plots import plot_training_analysis, plot_random_images, plot_candidates, print_false_values\n",
    "from Tests import test_data\n",
    "from BasicConvolutionalNetwork import BasicConvolutionalNetwork # Conseillé\n",
    "from VGG16Network import VGG16Network                           # Déconseillé : trop lent\n",
    "from InceptionV3Network import InceptionV3Network               # Déconseillé : apprentissage inadéquat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Partie 1** : simple-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Paramètres de la base de données</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE1 = 65\n",
    "labels1 = ['Apples-Braeburn', 'Apples-Granny-Smith', 'Apricots', 'Clementines','Corns',\n",
    "           'Cucumber-Ripes', 'Green-Peppers', 'Kiwis', 'Lemons', 'Limes',\n",
    "           'Mangos', 'Onions', 'Oranges', 'Peaches', 'Pineapples',\n",
    "           'Red-Peppers', 'Strawberries', 'Tomatoes', 'Watermelons']\n",
    "\n",
    "x_train1, y_train1 = load_data(path1, labels1, _imagesize=IMAGE_SIZE1)\n",
    "x_val1, y_val1 = load_data(path1, labels1, _dataset='validation', _imagesize=IMAGE_SIZE1)\n",
    "x_simpleTest, y_simpleTest = load_data(path1, labels1, _dataset='simple-test', _imagesize=IMAGE_SIZE1)\n",
    "\n",
    "plot_random_images(x_train1, y_train1, labels1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Lancement de l'entraînement</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_datagen.flow(x_train1, y_train1)\n",
    "val_generator = train_datagen.flow(x_val1, y_val1)\n",
    "\n",
    "model1 = BasicConvolutionalNetwork(len(labels1), IMAGE_SIZE1)\n",
    "\n",
    "model1.build(input_shape=(None, IMAGE_SIZE1, IMAGE_SIZE1, 3))\n",
    "model1.summary()\n",
    "model1.compile(loss='sparse_categorical_crossentropy',\n",
    "               optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "               metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history = model1.fit(train_generator, \n",
    "                     validation_data=val_generator,\n",
    "                     epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analyse post-entraînement</b>\n",
    "- <b>Prédiction de la classe</b> éventuelle d'une image test prise aléatoirement dans la base de donnée.\n",
    "- <b>Evalutation du modèle</b> dans sa globalité.\n",
    "- *(Affichage éventuel des prédictions râtées.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data(model1, labels1, x_simpleTest, y_simpleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EVALUATION DU MODELE \" + model1.name)\n",
    "loss_and_metrics = model1.evaluate(x_simpleTest, y_simpleTest, batch_size=10)\n",
    "print(\"LOSS     : {0:.2f}\".format(loss_and_metrics[0]))\n",
    "print(\"ACCURACY : {0:.2f}%\".format(loss_and_metrics[1] * 100))\n",
    "\n",
    "plot_training_analysis(history, 'sparse_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_false_values(model1, labels1, x_simpleTest, y_simpleTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Efficacité de *simple-database* sur une base de test réaliste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_realisticTest, y_realisticTest = load_data(path1, labels1, _dataset='realistic-test', _imagesize=IMAGE_SIZE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data(model1, labels1, x_realisticTest, y_realisticTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EVALUATION DU MODELE \" + model1.name)\n",
    "loss_and_metrics = model1.evaluate(x_realisticTest, y_realisticTest, batch_size=10)\n",
    "print(\"LOSS     : {0:.2f}\".format(loss_and_metrics[0]))\n",
    "print(\"ACCURACY : {0:.2f}%\".format(loss_and_metrics[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que le présent modèle est bien mauvais pour prédire la classe d'une image plus réaliste, plus complexe qu'un unique fruit sur fond blanc. Il vient donc l'idée d'élaborer une base de données réaliste dans un premier temps, puis hybride."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Partie 2** : realistic-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paramètres de la base de données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE2 = 65\n",
    "labels2 = ['apples', 'bananas', 'coconuts', 'grapes','lemons',\n",
    "           'limes', 'mangos', 'oranges', 'pineapples', 'tomatoes']\n",
    "\n",
    "x_train2, y_train2 = load_data(path2, labels2, _imagesize=IMAGE_SIZE2)\n",
    "x_val2, y_val2 = load_data(path2, labels2, _dataset='validation', _imagesize=IMAGE_SIZE2)\n",
    "x_test2, y_test2 = load_data(path2, labels2, _dataset='test', _imagesize=IMAGE_SIZE2)\n",
    "\n",
    "plot_random_images(x_train2, y_train2, labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lancement de l'entraînement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_datagen.flow(x_train2, y_train2)\n",
    "val_generator = train_datagen.flow(x_val2, y_val2)\n",
    "\n",
    "model2 = BasicConvolutionalNetwork(len(labels2), IMAGE_SIZE2)\n",
    "\n",
    "model2.build(input_shape=(None, IMAGE_SIZE2, IMAGE_SIZE2, 3))\n",
    "model2.summary()\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "               optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "               metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history = model2.fit(train_generator, \n",
    "                     validation_data=val_generator,\n",
    "                     epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analyse post-entraînement</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data(model2, labels2, x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EVALUATION DU MODELE \" + model2.name)\n",
    "loss_and_metrics = model2.evaluate(x_test2, y_test2, batch_size=10)\n",
    "print(\"LOSS     : {0:.2f}\".format(loss_and_metrics[0]))\n",
    "print(\"ACCURACY : {0:.2f}%\".format(loss_and_metrics[1] * 100))\n",
    "\n",
    "plot_training_analysis(history, 'sparse_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_false_values(model2, labels2, x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le précédent résultat n'étant pas satisfaisant, étudions les performances d'une base de données hybride entre la première et la deuxième."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Partie 3** : hybrid-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paramètres de la base de données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE3 = 100\n",
    "labels3 = ['apples', 'bananas', 'coconuts', 'grapes','lemons',\n",
    "           'limes', 'mangos', 'oranges', 'pineapples', 'tomatoes']\n",
    "\n",
    "x_train3, y_train3 = load_data(path3, labels3, _imagesize=IMAGE_SIZE3)\n",
    "x_val3, y_val3 = load_data(path3, labels3, _dataset='validation', _imagesize=IMAGE_SIZE3)\n",
    "x_test3, y_test3 = load_data(path3, labels3, _dataset='test', _imagesize=IMAGE_SIZE3)\n",
    "\n",
    "plot_random_images(x_train3, y_train3, labels3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lancement de l'entraînement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_datagen.flow(x_train3, y_train3)\n",
    "val_generator = train_datagen.flow(x_val3, y_val3)\n",
    "\n",
    "model3 = BasicConvolutionalNetwork(len(labels3), IMAGE_SIZE3)\n",
    "\n",
    "model3.build(input_shape=(None, IMAGE_SIZE3, IMAGE_SIZE3, 3))\n",
    "model3.summary()\n",
    "model3.compile(loss='sparse_categorical_crossentropy',\n",
    "               optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "               metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history = model3.fit(train_generator, \n",
    "                     validation_data=val_generator,\n",
    "                     epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analyse post-entraînement</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data(model3, labels3, x_test3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EVALUATION DU MODELE \" + model3.name)\n",
    "loss_and_metrics = model3.evaluate(x_test3, y_test3, batch_size=10)\n",
    "print(\"LOSS     : {0:.2f}\".format(loss_and_metrics[0]))\n",
    "print(\"ACCURACY : {0:.2f}%\".format(loss_and_metrics[1] * 100))\n",
    "\n",
    "plot_training_analysis(history, 'sparse_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_false_values(model3, labels3, x_test3, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analyse des résultats**\n",
    "\n",
    "*simple-database* affiche une précision de l'ordre de 95 à 100%, *realistic-database* une précision de 65 à 75%, et *hybrid-database* une précision de 80 à 85%.\n",
    "\n",
    "Qu'en conclure ?\n",
    "\n",
    "- Les résultats de la première BD sont très bons car une photo se présente toujours sous la forme d'un fruit sur fond blanc. Il est donc aisé pour le modèle d'apprendre la forme et la couleur du fruit. En revanche, il se montre assez mauvais pour classifier des images de fruits plus réalistes, d'où l'idée d'élaborer une base de données réaliste puis hybride.\n",
    "- Dans la deuxième BD, les choses se compliquent. Les fruits sont rarement seuls, parfois ils sont coupés en deux, et souvent ils sont posés sur une table, ce qui change du simple fond blanc. En terme de couleur, il y a beaucoup plus d'informations, en terme de forme, c'est plus délicat aussi, et désormais l'intérieur du fruit compte. Il y a plus d'informations à gérer, donc statistiquement cela se traduit par une précision plus faible.\n",
    "- Partant de là, nous décidâmes d'élaborer une approche hybride, et de construire une BD intégrant des éléments de la première et de la deuxième. Le but étant, à la fois de mémoriser au mieux la forme et la couleur de chaque fruit, et de pouvoir corréler ces informations à un contexte plus réaliste. Le résultat, s'il n'est pas transcendant (le trop plein d'informations l'oblige), demeure convenable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Annexe** : Quels fruits sont-ils ?\n",
    "\n",
    "*Les candidats à l'élection maraîchère de 2022 se prêtent à l'exercice...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_electionTest, _ = load_data(path1, labels1, _dataset=\"election-test\", _imagesize=IMAGE_SIZE1)\n",
    "plot_candidates(model1, labels1, x_electionTest)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca2c4d9748482125a2efb2d7bf5038335fd5286ddf123df9e4aea6c8bae6587f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
