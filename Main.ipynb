{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet : Deep Learning\n",
    "*Par Arthur Couturier, Enzo Di Maria, José Colin, Rémi Bonrepaux & Yassir El Bsita*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Classification d'images de fruits :</b> *apples, bananas, coconuts, grapes, lemons, limes, mangos, oranges, pineapples, tomatoes*.\n",
    "\n",
    "<b>Lien vers la doc :</b> https://keras.io/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Accès à la base de données ainsi qu'aux scripts </b>\n",
    "1. <b>Version distante :</b> Vous utilisez Google Colab. Dans ce cas vous devrez cloner le dépôt GitHub en exécutant la portion (1) du code ci-dessous.\n",
    "2. <b>Version locale :</b> Vous utilisez Visual Studio Code ou Jupyter Notebook. Dès lors, vous devrez simplement exécuter la portion (2) du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version distante (1)\n",
    "# !git clone https://github.com/EnzoN7/Image-classification.git\n",
    "# path = \"./Image-classification/images/\"\n",
    "# sys.path.insert(1, \"./Image-classification/scripts/\")\n",
    "# sys.path.insert(1, \"./Image-classification/models/\")\n",
    "\n",
    "# Version locale (2)\n",
    "path = \"./images/\"\n",
    "sys.path.insert(1, \"./scripts\")\n",
    "sys.path.insert(1, \"./models\")\n",
    "\n",
    "# (1) et (2)\n",
    "from LoadData import load_data\n",
    "from PlotTrainingAnalysis import plot_training_analysis\n",
    "from Tests import test_data, test_model\n",
    "from BasicConvolutionalNetwork import BasicConvolutionalNetwork\n",
    "from VGG16Network import VGG16Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Stockage des fichiers au sein de tenseurs </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = ['apples', 'bananas', 'coconuts', 'grapes', 'lemons', 'limes', 'mangos', 'oranges', 'pineapples', 'tomatoes']\n",
    "labels = ['apples', 'mangos', 'tomatoes']\n",
    "\n",
    "x_train, y_train = load_data(path, labels)\n",
    "x_val, y_val = load_data(path, labels, _dataset='validation')\n",
    "x_test, y_test = load_data(path, labels, _dataset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Affichage d'une sélection d'images aléatoire pour vérifier que l'importation s'est bien déroulée </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "shuffle_indices = np.random.permutation(9)\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.title(labels[int(y_train[shuffle_indices[i]])])\n",
    "    plt.imshow(x_train[shuffle_indices[i]])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Lancement de l'entraînement</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "METRICS = 'sparse_categorical_accuracy'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "model = BasicConvolutionalNetwork(len(labels), IMAGE_SIZE)\n",
    "model.build(input_shape=(None, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=3e-4),\n",
    "              metrics=[METRICS])\n",
    "\n",
    "history = model.fit(train_datagen.flow(x_train, y_train, batch_size=10), \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analyse post-entraînement</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_analysis(history, METRICS)\n",
    "\n",
    "# On teste la fidélité sur un exemple au hasard\n",
    "idx = randint(0, len(x_test) - 1)\n",
    "test_data(model, labels, idx, len(x_test) - 1, x_test[idx], y_test[idx], True)\n",
    "\n",
    "# Ici on teste la fiabilité du modèle dans son ensemble\n",
    "test_model(model, labels, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca2c4d9748482125a2efb2d7bf5038335fd5286ddf123df9e4aea6c8bae6587f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
